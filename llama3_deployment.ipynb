{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers boto3 \"sagemaker>=2.224.4\" awscli==1.33.24 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Retrieve SageMaker Execution Role ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "    print(\"Running in SageMaker notebook instance\")\n",
    "except ValueError:\n",
    "    # Specify profile name, region name and role name for local environment\n",
    "    ROLE_NAME = \"<ROLE_NAME>\"\n",
    "    PROFILE_NAME = \"default\"\n",
    "    REGION_NAME = \"us-east-1\"\n",
    "\n",
    "    # Initialize a boto3 session for local environment\n",
    "    session = boto3.Session(profile_name=PROFILE_NAME, region_name=REGION_NAME)\n",
    "\n",
    "    # Get sagemaker execution role ARN\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName=ROLE_NAME)['Role']['Arn']\n",
    "    print(\"Running in local environment\")\n",
    "    \n",
    "print(f\"Execution Role Arn: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_secret_manager import get_secret\n",
    "\n",
    "HF_MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "HF_TASK = \"text-generation\"\n",
    "# Get Hugging Face Hub token from AWS Secrets Manager\n",
    "HF_TOKEN = get_secret()[\"HUGGINGFACE_HUB_TOKEN\"]\n",
    "\n",
    "# Configure the environment for the model\n",
    "env = {\n",
    "    \"HF_MODEL_ID\": HF_MODEL_ID,\n",
    "    \"HF_TASK\": HF_TASK,\n",
    "    \"HUGGING_FACE_HUB_TOKEN\": HF_TOKEN,\n",
    "    \"MESSAGES_API_ENABLED\": \"true\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create the Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.3.0-tgi2.0.2-gpu-py310-cu121-ubuntu22.04\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "# Ensure endpoint name is compliant for AWS\n",
    "regex = r\"[^\\-a-zA-Z0-9]+\"\n",
    "model_name = re.sub(regex, \"-\", env[\"HF_MODEL_ID\"])\n",
    "\n",
    "# Get the Hugging Face LLM image URI\n",
    "image_uri = get_huggingface_llm_image_uri(\"huggingface\", version=\"2.0.2\")\n",
    "print(f'llm image uri: {image_uri}')\n",
    "\n",
    "# create model itself\n",
    "model = HuggingFaceModel(\n",
    "    name=model_name,\n",
    "    env=env,  # configuration for loading model from Hub\n",
    "    role=role,  # IAM role with permissions to create an endpoint\n",
    "    image_uri=image_uri,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Deploy the Model to AWS SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint_name: meta-llama-Meta-Llama-3-8B-Instruct-2024-07-20-18-08-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: meta-llama-Meta-Llama-3-8B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "instance_type = \"ml.g5.2xlarge\"  # Hardware recommendations for Llama 8B\n",
    "init_instance_count = 1\n",
    "health_check_timeout = 200\n",
    "\n",
    "# Generate a unique endpoint name using datetime\n",
    "endpoint_name = f'{model_name}-{datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=init_instance_count,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a helpful assistant.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Tell me about AWS SageMaker\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS SageMaker is a fully managed service offered by Amazon Web Services (AWS) that provides a range of tools and capabilities to build, train, and deploy machine learning (ML) models. SageMaker simplifies the ML workflow by providing a comprehensive platform\n"
     ]
    }
   ],
   "source": [
    "# Send a test request to the deployed endpoint\n",
    "input_data = {\n",
    "    \"messages\": messages,\n",
    "    \"model\":HF_MODEL_ID,\n",
    "    \"max_tokens\": 50, \n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "# Print the prediction result\n",
    "print(predictor.predict(input_data)['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Invoke the Endpoint with `sagemaker-runtime` Client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a helpful financial advisor.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What are the most profitable stocks of all time?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"max_tokens\":4000,\n",
    "              \"temperature\": 0.5, \n",
    "              \"top_p\": 0.2, \n",
    "              \"model\": HF_MODEL_ID\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def invoke_endpoint_for_inference(client, endpoint_name, messages, parameters):\n",
    "    payload = {\n",
    "    \"messages\": messages,\n",
    "    **parameters,\n",
    "    }\n",
    "    response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/json\",\n",
    "    Body=json.dumps(payload)\n",
    "    )\n",
    "\n",
    "    # Extract and print the response body\n",
    "    response_body = response['Body'].read().decode('utf-8')\n",
    "    response_json = json.loads(response_body)\n",
    "    generated_text = response_json['choices'][0]['message']['content']\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a great question! As a financial advisor, I'd be happy to share with you some of the most profitable stocks of all time. Keep in mind that past performance is not a guarantee of future results, and it's essential to do your own research and consider your individual financial goals and risk tolerance before investing in any stock.\n",
      "\n",
      "That being said, here are some of the most profitable stocks of all time:\n",
      "\n",
      "1. Amazon (AMZN) - Up over 100,000% since its IPO in 1997. Yes, you read that right! Amazon has been a game-changer in the e-commerce space and has disrupted numerous industries.\n",
      "2. Microsoft (MSFT) - Up over 50,000% since its IPO in 1986. Microsoft's dominance in the software industry, particularly with its Windows operating system, has made it a household name.\n",
      "3. Alphabet (GOOGL) - Up over 20,000% since its IPO in 2004. As the parent company of Google, Alphabet has revolutionized the way we search, advertise, and access information online.\n",
      "4. Facebook (FB) - Up over 10,000% since its IPO in 2012. Facebook's social media platform has become an integral part of modern life, and its advertising business has generated significant revenue.\n",
      "5. Johnson & Johnson (JNJ) - Up over 10,000% since its IPO in 1944. This healthcare giant has a diverse portfolio of pharmaceuticals, medical devices, and consumer products, making it a stable and profitable investment.\n",
      "6. Procter & Gamble (PG) - Up over 9,000% since its IPO in 1890. This consumer goods company has a long history of innovation and has developed iconic brands like Tide, Pampers, and Gillette.\n",
      "7. Coca-Cola (KO) - Up over 8,000% since its IPO in 1919. The world's largest beverage company has been a staple in many households for over a century, with a portfolio of brands that includes Fanta, Sprite, and Minute Maid.\n",
      "8. Visa (V) - Up over 7,000% since its IPO in 2008. As a leading payment technology company, Visa has benefited from the shift towards digital payments and has become a dominant player in the industry.\n",
      "9. Mastercard (MA) - Up over 6,000% since its IPO in 2006. Similar to Visa, Mastercard has also seen significant growth as the world becomes increasingly digital and cashless.\n",
      "10. Netflix (NFLX) - Up over 5,000% since its IPO in 2002. This streaming giant has disrupted the entertainment industry and has become a household name, offering a wide range of content to subscribers worldwide.\n",
      "\n",
      "Remember, these returns are exceptional and not typical of most stocks. It's essential to diversify your portfolio, set clear financial goals, and consider your risk tolerance before investing in any stock. As a financial advisor, I'd be happy to help you create a personalized investment plan tailored to your needs.\n"
     ]
    }
   ],
   "source": [
    "# Print the response\n",
    "\n",
    "client = session.client(service_name=\"sagemaker-runtime\", region_name=REGION_NAME)\n",
    "generated_text = invoke_endpoint_for_inference(client, endpoint_name, messages, parameters)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
